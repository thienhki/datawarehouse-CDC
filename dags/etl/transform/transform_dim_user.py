import psycopg2
from psycopg2.extras import execute_values
from datetime import datetime
from etl.common.checkpoint import CheckpointManager

# ---------- HELPERS ----------
def normalize_gender(g):
    if g == 'M': return 'Male'
    if g == 'F': return 'Female'
    return 'Unknown'

def age_group(age):
    if age is None: return 'Unknown'
    if age < 30: return "Young"
    if age < 55: return "Middle"
    return "Senior"

# ---------- ETL DIM USER ----------
def etl_dim_user(conn):
    cp = CheckpointManager()
    last_ts = cp.load("users")
    cur = conn.cursor()

    # 1ï¸âƒ£ Load tráº¡ng thÃ¡i hiá»‡n táº¡i
    print("ðŸš€ Loading current dim_user cache...")
    cur.execute("""
        SELECT user_id, user_sk, gender, age, age_group, traffic_source, city, state, country
        FROM dw.dim_user WHERE is_current = TRUE
    """)
    current_dim = {r[0]: r[1:] for r in cur.fetchall()}
    print(f"âœ… Loaded {len(current_dim)} active users")

    # 2ï¸âƒ£ Load CDC changes
    print("ðŸš€ Fetching CDC changes...")
    cur.execute("""
        SELECT id, gender, age, traffic_source, city, state, country, ts_ms
        FROM public.users
        WHERE ts_ms > %s AND op != 'd'
        ORDER BY ts_ms ASC
    """, (last_ts,))
    cdc_rows = cur.fetchall()
    print(f"âœ… Found {len(cdc_rows)} records")
    
    to_close = []
    to_insert = []
    max_ts = last_ts

    # 3ï¸âƒ£ Transform
    for r in cdc_rows:
        u_id, gender, age, traffic_source, city, state, country, ts_ms = r
        valid_from = datetime.fromtimestamp(ts_ms / 1000).date()
        max_ts = max(max_ts, ts_ms)

        g_norm = normalize_gender(gender)
        a_grp = age_group(age)
        new_val = (g_norm, age, a_grp, traffic_source, city, state, country)

        current = current_dim.get(u_id)
        
        if not current or current[1:] != new_val:
            if current: 
                to_close.append((valid_from, current[0]))
            to_insert.append((u_id, g_norm, age, a_grp, traffic_source, city, state, country, valid_from))

    # 4ï¸âƒ£ Apply Batch Updates
    if to_close:
        print(f"ðŸ” Closing {len(to_close)} old versions...")
        execute_values(cur, """
            UPDATE dw.dim_user SET is_current = FALSE, valid_to = v.v_to::date
            FROM (VALUES %s) AS v(v_to, sk) WHERE user_sk = v.sk::integer
        """, to_close)

    if to_insert:
        print(f"âž• Inserting {len(to_insert)} new versions...")
        execute_values(cur, """
            INSERT INTO dw.dim_user 
            (user_id, gender, age, age_group, traffic_source, city, state, country, valid_from, valid_to, is_current)
            VALUES %s
        """, [(*r, None, True) for r in to_insert])
    
    # QUAN TRá»ŒNG: KhÃ´ng Ä‘Ã³ng conn á»Ÿ Ä‘Ã¢y náº¿u dÃ¹ng Airflow Ä‘iá»u phá»‘i
    cur.close()

    # Tráº£ vá» cÃ¡c thÃ´ng sá»‘ Ä‘á»ƒ DAG xá»­ lÃ½ tiáº¿p (commit, save checkpoint, logging)
    return max_ts, len(to_insert), len(to_close)

# Cho phÃ©p cháº¡y Ä‘á»™c láº­p Ä‘á»ƒ test
if __name__ == "__main__":
    from etl.common.database import get_dw_conn
    connection = get_dw_conn()
    try:
        m_ts, inc, cls = etl_dim_user(connection)
        connection.commit()
        if m_ts > 0:
            CheckpointManager().save("users", m_ts)
        print(f"ðŸŽ‰ TEST DONE | New: {inc} | Closed: {cls}")
    finally:
        connection.close()